import streamlit as st
import yfinance as yf
import pandas as pd
import requests
import math
import urllib3
from io import StringIO
from datetime import datetime, timedelta
from streamlit_gsheets import GSheetsConnection

# åŸºç¤Žç’°å¢ƒè¨­å®š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
st.set_page_config(layout="wide", page_title="å°è‚¡é›²ç«¯ç¯©é¸ç³»çµ±")

# --- 1. åŒæ­¥èˆ‡è®€å–å‡½æ•¸ (å®šç¾©åœ¨æœ€ä¸Šæ–¹é¿å… NameError) ---
def sync_to_sheets(watchlist):
    try:
        conn = st.connection("gsheets", type=GSheetsConnection)
        new_df = pd.DataFrame({"ticker_item": watchlist})
        conn.update(worksheet="Sheet1", data=new_df)
        return True
    except Exception as e:
        st.error(f"âŒ åŒæ­¥å¤±æ•—ï¼š{e}")
        return False

def load_watchlist():
    try:
        conn = st.connection("gsheets", type=GSheetsConnection)
        df = conn.read(worksheet="Sheet1", ttl="0")
        return df["ticker_item"].dropna().unique().tolist() if not df.empty else []
    except:
        return []

# --- 2. åˆå§‹åŒ–èˆ‡æ•¸æ“šæŠ“å– ---
if 'watchlist' not in st.session_state:
    st.session_state['watchlist'] = load_watchlist()

@st.cache_data(ttl=3600)
def get_cleaned_tickers():
    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    res = requests.get(url, verify=False)
    df = pd.read_html(StringIO(res.text))[0].iloc[1:]
    return [f"{str(val).split('ã€€')[0]}.TW,{str(val).split('ã€€')[1]}" for val in df[0] 
            if 'ã€€' in str(val) and str(val).split('ã€€')[0].isdigit()]

def fetch_stock_data(tickers_with_names, low_chg, high_chg, low_vol, high_vol, low_turn, high_turn):
    if not tickers_with_names: return pd.DataFrame()
    mapping = {t.split(',')[0]: t.split(',')[1] for t in tickers_with_names}
    # æ¢å¾©çœŸå¯¦æŠ“å–æ•¸æ“šï¼Œç§»é™¤å¯«æ­»çš„ 2330
    data = yf.download(list(mapping.keys()), period="6d", group_by='ticker', progress=False)
    if data.empty: return pd.DataFrame()
    
    results = []
    for t in mapping.keys():
        try:
            t_data = data[t] if len(mapping) > 1 else data
            if t_data.empty: continue
            c_now, c_pre = t_data['Close'].iloc[-1], t_data['Close'].iloc[-2]
            change = round(((c_now - c_pre) / c_pre) * 100, 2)
            vol_ratio = round(t_data['Volume'].iloc[-1] / t_data['Volume'].iloc[:-1].mean(), 2)
            
            if low_chg <= change <= high_chg and low_vol <= vol_ratio <= high_vol:
                results.append({"é¸å–": False, "è‚¡ç¥¨ä»£è™Ÿ": t, "åç¨±": mapping[t], "æ¼²å¹…": change, "é‡æ¯”": vol_ratio})
        except: continue
    return pd.DataFrame(results)

# --- 3. ä»‹é¢é‚è¼¯ ---
st.sidebar.title("ðŸš€ è‚¡å¸‚å°Žèˆªé¸å–®")
page = st.sidebar.radio("è«‹é¸æ“‡é é¢ï¼š", ["å…¨å¸‚å ´åˆ†çµ„æŽƒæ", "æˆ‘çš„é—œæ³¨æ¸…å–®"])

if page == "å…¨å¸‚å ´åˆ†çµ„æŽƒæ":
    st.header("âš–ï¸ å°è‚¡å…¨å¸‚å ´ç²¾ç¢ºç¯©é¸ç³»çµ±")
    tickers = get_cleaned_tickers()
    sel_g = st.sidebar.selectbox("1. é¸æ“‡æŽƒæç¾¤çµ„", [f"ç¬¬ {i+1} çµ„" for i in range(math.ceil(len(tickers)/100))])
    
    if st.button("ðŸš€ é–‹å§‹æŽƒæ"):
        target = tickers[int(sel_g.split(' ')[1])*100-100 : int(sel_g.split(' ')[1])*100]
        st.session_state['scan_res'] = fetch_stock_data(target, 0.0, 10.0, 1.0, 99.0, 0.5, 99.0)

    if 'scan_res' in st.session_state:
        # ä¿®æ­£ï¼šæ”¹å›ž use_container_width=True ä»¥è§£æ±º WidthError
        edit_df = st.data_editor(st.session_state['scan_res'], hide_index=True, use_container_width=True, key="editor")
        if st.button("âž• åŠ å…¥ Google Sheets"):
            to_add = edit_df[edit_df["é¸å–"] == True]
            for _, r in to_add.iterrows():
                st.session_state['watchlist'].append(f"{r['è‚¡ç¥¨ä»£è™Ÿ']},{r['åç¨±']}")
            if sync_to_sheets(st.session_state['watchlist']):
                st.success("åŒæ­¥æˆåŠŸï¼")
